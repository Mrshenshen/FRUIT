model:
  arch: mini_gpt4
  model_type:  pretrain_vicuna # pretrain_llama2 pretrain_vicuna
  freeze_vit: True
  q_former_model: "/VLMs/blip/blip2_pretrained_flant5xxl.pth"
  llama_model:  "/VLMs/vicuna"
  freeze_qformer: True
  max_txt_len: 160
  end_sym: "###"
  low_resource: False
  prompt_path: "FRUIT/models/minigpt4_legacy/minigpt4_eval.yaml"
  prompt_template: '###Human: {} ###Assistant: '
  ckpt:  "/VLMs/model_checkpoints/pretrained_minigpt4_13b.pth" #"/VLMs/MiniGPT-4/checkpoint/prerained_minigpt4_7b.pth"


preprocess:
  vis_processor:
    train:
      name: "blip2_image_train"
      image_size: 224
    eval:
      name: "blip2_image_eval"
      image_size: 224
  text_processor:
    train:
      name: "blip_caption"
    eval:
      name: "blip_caption"


run:
  task: image_text_pretrain
